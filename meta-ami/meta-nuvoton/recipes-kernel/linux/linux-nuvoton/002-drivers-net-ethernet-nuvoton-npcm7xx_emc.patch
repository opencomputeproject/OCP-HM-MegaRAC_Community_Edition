--- a/drivers/net/ethernet/nuvoton/npcm7xx_emc.c	2020-08-20 12:28:55.609940191 -0400
+++ b/drivers/net/ethernet/nuvoton/npcm7xx_emc.c	2020-08-20 12:30:42.578910053 -0400
@@ -20,6 +20,7 @@
 #include <linux/spinlock.h>
 #include <linux/ctype.h>
 #include <linux/debugfs.h>
+#include <linux/reset.h>
 
 #include <linux/clk.h>
 
@@ -47,7 +48,7 @@
 #define  IPSRST1_OFFSET 0x020
 
 #define DRV_MODULE_NAME		"npcm7xx-emc"
-#define DRV_MODULE_VERSION	"3.90"
+#define DRV_MODULE_VERSION	"3.94"
 
 /* Ethernet MAC Registers */
 #define REG_CAMCMR	0x00
@@ -97,14 +98,14 @@
 #define MCMDR_OPMOD		BIT(20)
 #define SWR			BIT(24)
 
-/* cam command regiser */
+/* cam command register */
 #define CAMCMR_AUP		BIT(0)
 #define CAMCMR_AMP		BIT(1)
 #define CAMCMR_ABP		BIT(2)
 #define CAMCMR_CCAM		BIT(3)
 #define CAMCMR_ECMP		BIT(4)
 
-/* cam enable regiser */
+/* cam enable register */
 #define CAM0EN			BIT(0)
 
 /* mac mii controller bit */
@@ -203,8 +204,8 @@
 #define IS_VLAN 0
 #endif
 
-#define MAX_PACKET_SIZE           (1514 + (IS_VLAN * 4))
-#define MAX_PACKET_SIZE_W_CRC     (MAX_PACKET_SIZE + 4) /* 1518 */
+#define MAX_PACKET_SIZE           (ETH_FRAME_LEN + (IS_VLAN * VLAN_HLEN))
+#define MAX_PACKET_SIZE_W_CRC     (MAX_PACKET_SIZE + ETH_FCS_LEN) /* 1518 */
 
 #define MHZ (1000 * 1000)
 #define MII_TIMEOUT	100
@@ -239,7 +240,7 @@
 	dma_addr_t tdesc_phys;
 	struct net_device_stats stats;
 	struct platform_device *pdev;
-	struct net_device *ndev;
+	struct net_device *netdev;
 	struct resource *res;
 	unsigned int msg_enable;
 	struct mii_bus *mii_bus;
@@ -254,20 +255,24 @@
 	unsigned int cur_rx;
 	unsigned int finish_tx;
 	unsigned int pending_tx;
-	__le32 start_tx_ptr;
-	__le32 start_rx_ptr;
+	u32 start_tx_ptr;
+	u32 start_rx_ptr;
 	unsigned int rx_berr;
 	unsigned int rx_err;
 	unsigned int rdu;
 	unsigned int rxov;
-	__le32 camcmr;
+	u32 camcmr;
 	unsigned int rx_stuck;
 	int link;
 	int speed;
 	int duplex;
 	int need_reset;
 	char *dump_buf;
-	struct regmap *rst_regmap;
+	struct reset_control *reset;
+
+	/* Scratch page to use when rx skb alloc fails */
+	void *rx_scratch;
+	dma_addr_t rx_scratch_dma;
 
 	/* debug counters */
 	unsigned int max_waiting_rx;
@@ -290,13 +295,13 @@
 
 #if defined CONFIG_NPCM7XX_EMC_ETH_DEBUG || defined CONFIG_DEBUG_FS
 #define REG_PRINT(reg_name) {t = scnprintf(next, size, "%-10s = %08X\n", \
-	#reg_name, readl(ether->reg + reg_name)); size -= t;	next += t; }
+	#reg_name, readl(ether->reg + (reg_name))); size -= t;	next += t; }
 #define DUMP_PRINT(f, x...) {t = scnprintf(next, size, f, ## x); size -= t; \
 	next += t; }
 
-static int npcm7xx_info_dump(char *buf, int count, struct net_device *dev)
+static int npcm7xx_info_dump(char *buf, int count, struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct npcm7xx_txbd *txbd;
 	struct npcm7xx_rxbd *rxbd;
 	unsigned long flags;
@@ -310,7 +315,7 @@
 		spin_lock_irqsave(&ether->lock, flags);
 
 	/* ------basic driver information ---- */
-	DUMP_PRINT("NPCM7XX EMC %s driver version: %s\n", dev->name,
+	DUMP_PRINT("NPCM7XX EMC %s driver version: %s\n", netdev->name,
 		   DRV_MODULE_VERSION);
 
 	REG_PRINT(REG_CAMCMR);
@@ -348,7 +353,7 @@
 	REG_PRINT(REG_BISTR);
 	DUMP_PRINT("\n");
 
-	DUMP_PRINT("netif_queue %s\n\n", netif_queue_stopped(dev) ?
+	DUMP_PRINT("netif_queue %s\n\n", netif_queue_stopped(netdev) ?
 					"Stopped" : "Running");
 	if (ether->rdesc)
 		DUMP_PRINT("napi is %s\n\n", test_bit(NAPI_STATE_SCHED,
@@ -411,8 +416,12 @@
 			cur = (cur + 1) % TX_QUEUE_LEN;
 			txbd = (ether->tdesc + cur);
 			DUMP_PRINT("finish %3d txbd mode %08X buffer %08X sl %08X next %08X tx_skb %p\n",
-				   cur, txbd->mode, txbd->buffer,
-				   txbd->sl, txbd->next, ether->tx_skb[cur]);
+				   cur,
+				   le32_to_cpu(txbd->mode),
+				   le32_to_cpu(txbd->buffer),
+				   le32_to_cpu(txbd->sl),
+				   le32_to_cpu(txbd->next),
+				   ether->tx_skb[cur]);
 		}
 		DUMP_PRINT("\n");
 
@@ -421,8 +430,11 @@
 			cur = (cur + 1) % TX_QUEUE_LEN;
 			txbd = (ether->tdesc + cur);
 			DUMP_PRINT("txd_of %3d txbd mode %08X buffer %08X sl %08X next %08X\n",
-				   cur, txbd->mode, txbd->buffer,
-				   txbd->sl, txbd->next);
+				   cur,
+				   le32_to_cpu(txbd->mode),
+				   le32_to_cpu(txbd->buffer),
+				   le32_to_cpu(txbd->sl),
+				   le32_to_cpu(txbd->next));
 		}
 		DUMP_PRINT("\n");
 
@@ -431,8 +443,11 @@
 			cur = (cur + 1) % TX_QUEUE_LEN;
 			txbd = (ether->tdesc + cur);
 			DUMP_PRINT("cur_tx %3d txbd mode %08X buffer %08X sl %08X next %08X\n",
-				   cur, txbd->mode, txbd->buffer,
-				   txbd->sl, txbd->next);
+				   cur,
+				   le32_to_cpu(txbd->mode),
+				   le32_to_cpu(txbd->buffer),
+				   le32_to_cpu(txbd->sl),
+				   le32_to_cpu(txbd->next));
 		}
 		DUMP_PRINT("\n");
 
@@ -441,8 +456,11 @@
 			cur = (cur + 1) % RX_QUEUE_LEN;
 			rxbd = (ether->rdesc + cur);
 			DUMP_PRINT("cur_rx %3d rxbd sl   %08X buffer %08X sl %08X next %08X\n",
-				   cur, rxbd->sl, rxbd->buffer,
-				   rxbd->reserved, rxbd->next);
+				   cur,
+				   le32_to_cpu(rxbd->sl),
+				   le32_to_cpu(rxbd->buffer),
+				   le32_to_cpu(rxbd->reserved),
+				   le32_to_cpu(rxbd->next));
 		}
 		DUMP_PRINT("\n");
 
@@ -451,8 +469,11 @@
 			cur = (cur + 1) % RX_QUEUE_LEN;
 			rxbd = (ether->rdesc + cur);
 			DUMP_PRINT("rxd_of %3d rxbd sl %08X buffer %08X sl %08X next %08X\n",
-				   cur, rxbd->sl, rxbd->buffer,
-				   rxbd->reserved, rxbd->next);
+				   cur,
+				   le32_to_cpu(rxbd->sl),
+				   le32_to_cpu(rxbd->buffer),
+				   le32_to_cpu(rxbd->reserved),
+				   le32_to_cpu(rxbd->next));
 		}
 		DUMP_PRINT("\n");
 	}
@@ -465,36 +486,35 @@
 #endif
 
 #ifdef CONFIG_NPCM7XX_EMC_ETH_DEBUG
-static void npcm7xx_info_print(struct net_device *dev)
+static void npcm7xx_info_print(struct net_device *netdev)
 {
 	char *emc_dump_buf;
 	int count;
 	struct npcm7xx_ether *ether;
 	struct platform_device *pdev;
+	char c;
+	char *tmp_buf;
 	const size_t print_size = 5 * PAGE_SIZE;
 
-	ether = netdev_priv(dev);
+	ether = netdev_priv(netdev);
 	pdev = ether->pdev;
 
 	emc_dump_buf = kmalloc(print_size, GFP_KERNEL);
-	if (!emc_dump_buf) {
-		dev_err(&pdev->dev, "kmalloc failed\n");
-	} else {
-		char c;
-		char *tmp_buf = emc_dump_buf;
+	if (!emc_dump_buf)
+		return;
 
-		count = npcm7xx_info_dump(emc_dump_buf, print_size, dev);
-		while (count > 512) {
-			c = tmp_buf[512];
-			tmp_buf[512] = 0;
-			dev_info(&pdev->dev, "%s", tmp_buf);
-			tmp_buf += 512;
-			tmp_buf[0] = c;
-			count -= 512;
-		}
+	tmp_buf = emc_dump_buf;
+	count = npcm7xx_info_dump(emc_dump_buf, print_size, netdev);
+	while (count > 512) {
+		c = tmp_buf[512];
+		tmp_buf[512] = 0;
 		dev_info(&pdev->dev, "%s", tmp_buf);
-		kfree(emc_dump_buf);
+		tmp_buf += 512;
+		tmp_buf[0] = c;
+		count -= 512;
 	}
+	dev_info(&pdev->dev, "%s", tmp_buf);
+	kfree(emc_dump_buf);
 }
 #endif
 
@@ -503,15 +523,15 @@
 
 static int npcm7xx_debug_show(struct seq_file *sf, void *v)
 {
-	struct net_device *dev = (struct net_device *)sf->private;
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	const size_t print_size = 5 * PAGE_SIZE;
+	struct net_device *netdev = (struct net_device *)sf->private;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	const size_t print_size = 0x5000; /* maximum print size needed */
 
 	if (!ether->dump_buf) {
 		ether->dump_buf = kmalloc(print_size, GFP_KERNEL);
 		if (!ether->dump_buf)
 			return -1;
-		npcm7xx_info_dump(ether->dump_buf, print_size, dev);
+		npcm7xx_info_dump(ether->dump_buf, print_size, netdev);
 	}
 
 	seq_printf(sf, "%s", ether->dump_buf);
@@ -537,8 +557,8 @@
 
 static int npcm7xx_debug_reset(struct seq_file *sf, void *v)
 {
-	struct net_device *dev = (struct net_device *)sf->private;
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct net_device *netdev = (struct net_device *)sf->private;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	unsigned long flags;
 
 	seq_puts(sf, "Ask to reset the module\n");
@@ -571,28 +591,32 @@
 		npcm7xx_fs_dir = debugfs_create_dir(DRV_MODULE_NAME, NULL);
 
 		if (!npcm7xx_fs_dir || IS_ERR(npcm7xx_fs_dir)) {
-			dev_err(&ether->pdev->dev, "ERROR %s, debugfs create directory failed\n",
+			dev_err(&ether->pdev->dev,
+				"ERROR %s, debugfs create directory failed\n",
 				DRV_MODULE_NAME);
 			return -ENOMEM;
 		}
 	}
 
 	/* Create per netdev entries */
-	ether->dbgfs_dir = debugfs_create_dir(ether->ndev->name,
+	ether->dbgfs_dir = debugfs_create_dir(ether->netdev->name,
 					      npcm7xx_fs_dir);
 	if (!ether->dbgfs_dir || IS_ERR(ether->dbgfs_dir)) {
-		dev_err(&ether->pdev->dev, "ERROR failed to create %s directory\n", ether->ndev->name);
+		dev_err(&ether->pdev->dev,
+			"ERROR failed to create %s directory\n",
+			ether->netdev->name);
 		return -ENOMEM;
 	}
 
 	/* Entry to report DMA RX/TX rings */
 	ether->dbgfs_status =
 		debugfs_create_file("status", 0444,
-				    ether->dbgfs_dir, ether->ndev,
+				    ether->dbgfs_dir, ether->netdev,
 				    &npcm7xx_debug_show_fops);
 
 	if (!ether->dbgfs_status || IS_ERR(ether->dbgfs_status)) {
-		dev_err(&ether->pdev->dev, "ERROR creating \'status\' debugfs file\n");
+		dev_err(&ether->pdev->dev,
+			"ERROR creating \'status\' debugfs file\n");
 		debugfs_remove_recursive(ether->dbgfs_dir);
 
 		return -ENOMEM;
@@ -601,11 +625,12 @@
 	/* Entry to report the DMA HW features */
 	ether->dbgfs_dma_cap = debugfs_create_file("do_reset", 0444,
 						   ether->dbgfs_dir,
-						   ether->ndev,
+						   ether->netdev,
 						   &npcm7xx_debug_reset_fops);
 
 	if (!ether->dbgfs_dma_cap || IS_ERR(ether->dbgfs_dma_cap)) {
-		dev_err(&ether->pdev->dev, "ERROR creating stmmac \'do_reset\' debugfs file\n");
+		dev_err(&ether->pdev->dev,
+			"ERROR creating \'do_reset\' debugfs file\n");
 		debugfs_remove_recursive(ether->dbgfs_dir);
 
 		return -ENOMEM;
@@ -615,10 +640,10 @@
 }
 #endif
 
-static void npcm7xx_opmode(struct net_device *dev, int speed, int duplex)
+static void npcm7xx_opmode(struct net_device *netdev, int speed, int duplex)
 {
-	__le32 val;
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	u32 val;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 
 	val = readl((ether->reg + REG_MCMDR));
 	if (speed == 100)
@@ -634,15 +659,11 @@
 	writel(val, (ether->reg + REG_MCMDR));
 }
 
-static void adjust_link(struct net_device *dev)
+static void adjust_link(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct phy_device *phydev = ether->phy_dev;
 	bool status_change = false;
-	unsigned long flags;
-
-	/* clear GPIO interrupt status whihc indicates PHY statu change? */
-	spin_lock_irqsave(&ether->lock, flags);
 
 	if (phydev->link) {
 		if (ether->speed != phydev->speed ||
@@ -661,17 +682,15 @@
 		status_change = true;
 	}
 
-	spin_unlock_irqrestore(&ether->lock, flags);
-
 	if (status_change)
-		npcm7xx_opmode(dev, ether->speed, ether->duplex);
+		npcm7xx_opmode(netdev, ether->speed, ether->duplex);
 }
 
-static void npcm7xx_write_cam(struct net_device *dev,
+static void npcm7xx_write_cam(struct net_device *netdev,
 			      unsigned int x, unsigned char *pval)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	__le32 msw, lsw;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	u32 msw, lsw;
 
 	msw = (pval[0] << 24) | (pval[1] << 16) | (pval[2] << 8) | pval[3];
 
@@ -679,33 +698,106 @@
 
 	writel(lsw, (ether->reg + REG_CAML_BASE) + x * CAM_ENTRY_SIZE);
 	writel(msw, (ether->reg + REG_CAMM_BASE) + x * CAM_ENTRY_SIZE);
-	dev_dbg(&ether->pdev->dev, "REG_CAML_BASE = 0x%08X REG_CAMM_BASE = 0x%08X", lsw, msw);
+	dev_dbg(&ether->pdev->dev,
+		"REG_CAML_BASE = 0x%08X REG_CAMM_BASE = 0x%08X", lsw, msw);
 }
 
-static struct sk_buff *get_new_skb(struct net_device *dev, u32 i)
+static struct sk_buff *get_new_skb(struct net_device *netdev, u32 i)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	struct sk_buff *skb = dev_alloc_skb(roundup(MAX_PACKET_SIZE_W_CRC, 4));
+	dma_addr_t buffer;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	struct sk_buff *skb = netdev_alloc_skb(netdev,
+		roundup(MAX_PACKET_SIZE_W_CRC, 4));
 
-	if (!skb)
-		return NULL;
-
-	/* Do not unmark the following skb_reserve() Receive Buffer Starting
-	 * Address must be aligned to 4 bytes and the following line
-	 * if unmarked will make it align to 2 and this likely will
-	 * hult the RX and crash the linux skb_reserve(skb, NET_IP_ALIGN);
-	 */
-	skb->dev = dev;
-	(ether->rdesc + i)->buffer =
-		dma_map_single(&dev->dev, skb->data,
-			       roundup(MAX_PACKET_SIZE_W_CRC, 4),
-			       DMA_FROM_DEVICE);
+	if (unlikely(!skb)) {
+		if (net_ratelimit())
+			netdev_warn(netdev, "failed to allocate rx skb\n");
+		buffer = ether->rx_scratch_dma;
+	} else {
+		/* Do not unmark the following skb_reserve() Receive Buffer
+		 * Starting Address must be aligned to 4 bytes and the following
+		 * line if unmarked will make it align to 2 and this likely will
+		 * halt the RX and crash the linux
+		 * skb_reserve(skb, NET_IP_ALIGN);
+		 */
+		skb->dev = netdev;
+		buffer = dma_map_single(&netdev->dev,
+					skb->data,
+					roundup(MAX_PACKET_SIZE_W_CRC, 4),
+					DMA_FROM_DEVICE);
+		if (unlikely(dma_mapping_error(&netdev->dev, buffer))) {
+			if (net_ratelimit())
+				netdev_err(netdev, "failed to map rx page\n");
+			dev_kfree_skb_any(skb);
+			buffer = ether->rx_scratch_dma;
+			skb = NULL;
+		}
+	}
 	ether->rx_skb[i] = skb;
+	ether->rdesc[i].buffer = cpu_to_le32(buffer);
 
 	return skb;
 }
 
-static int npcm7xx_init_desc(struct net_device *dev)
+/* This API must call with Tx/Rx stopped */
+static void npcm7xx_free_desc(struct net_device *netdev,
+			      bool free_also_descriptors)
+{
+	struct sk_buff *skb;
+	u32 i;
+	dma_addr_t addr;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	struct platform_device *pdev = ether->pdev;
+
+	for (i = 0; i < TX_QUEUE_LEN; i++) {
+		skb = ether->tx_skb[i];
+		if (skb) {
+			addr = (dma_addr_t)le32_to_cpu(ether->tdesc[i].buffer);
+			dma_unmap_single(&netdev->dev, addr, skb->len,
+					 DMA_TO_DEVICE);
+			dev_kfree_skb_any(skb);
+			ether->tx_skb[i] = NULL;
+		}
+	}
+
+	for (i = 0; i < RX_QUEUE_LEN; i++) {
+		skb = ether->rx_skb[i];
+		if (skb) {
+			addr = (dma_addr_t)le32_to_cpu(ether->rdesc[i].buffer);
+			dma_unmap_single(&netdev->dev, addr,
+					 roundup(MAX_PACKET_SIZE_W_CRC, 4),
+					 DMA_FROM_DEVICE);
+			dev_kfree_skb_any(skb);
+			ether->rx_skb[i] = NULL;
+		}
+	}
+
+	if (free_also_descriptors) {
+		if (ether->tdesc)
+			dma_free_coherent(&pdev->dev,
+					  sizeof(struct npcm7xx_txbd) *
+					  TX_QUEUE_LEN,
+					  ether->tdesc, ether->tdesc_phys);
+		ether->tdesc = NULL;
+
+		if (ether->rdesc)
+			dma_free_coherent(&pdev->dev,
+					  sizeof(struct npcm7xx_rxbd) *
+					  RX_QUEUE_LEN,
+					  ether->rdesc, ether->rdesc_phys);
+		ether->rdesc = NULL;
+
+		/* Free scratch packet buffer */
+		if (ether->rx_scratch)
+			dma_free_coherent(&pdev->dev,
+					  roundup(MAX_PACKET_SIZE_W_CRC, 4),
+					  ether->rx_scratch,
+					  ether->rx_scratch_dma);
+		ether->rx_scratch = NULL;
+	}
+}
+
+static int npcm7xx_init_desc(struct net_device *netdev)
 {
 	struct npcm7xx_ether *ether;
 	struct npcm7xx_txbd  *tdesc;
@@ -713,7 +805,7 @@
 	struct platform_device *pdev;
 	unsigned int i;
 
-	ether = netdev_priv(dev);
+	ether = netdev_priv(netdev);
 	pdev = ether->pdev;
 
 	if (!ether->tdesc) {
@@ -725,7 +817,9 @@
 						   GFP_KERNEL);
 
 		if (!ether->tdesc) {
-			dev_err(&pdev->dev, "Failed to allocate memory for tx desc\n");
+			dev_err(&pdev->dev,
+				"Failed to allocate memory for tx desc\n");
+			npcm7xx_free_desc(netdev, true);
 			return -ENOMEM;
 		}
 	}
@@ -739,12 +833,9 @@
 						   GFP_KERNEL);
 
 		if (!ether->rdesc) {
-			dev_err(&pdev->dev, "Failed to allocate memory for rx desc\n");
-			dma_free_coherent(&pdev->dev,
-					  sizeof(struct npcm7xx_txbd) *
-					  TX_QUEUE_LEN, ether->tdesc,
-					  ether->tdesc_phys);
-			ether->tdesc = NULL;
+			dev_err(&pdev->dev,
+				"Failed to allocate memory for rx desc\n");
+			npcm7xx_free_desc(netdev, true);
 			return -ENOMEM;
 		}
 	}
@@ -759,14 +850,28 @@
 		else
 			offset = sizeof(struct npcm7xx_txbd) * (i + 1);
 
-		tdesc->next = ether->tdesc_phys + offset;
-		tdesc->buffer = (__le32)NULL;
+		tdesc->next = cpu_to_le32(ether->tdesc_phys + offset);
+		tdesc->buffer = cpu_to_le32(NULL);
 		tdesc->sl = 0;
 		tdesc->mode = 0;
 	}
 
 	ether->start_tx_ptr = ether->tdesc_phys;
 
+	/* Allocate scratch packet buffer */
+	if (!ether->rx_scratch) {
+		ether->rx_scratch =
+			dma_alloc_coherent(&pdev->dev,
+					   roundup(MAX_PACKET_SIZE_W_CRC, 4),
+					   &ether->rx_scratch_dma, GFP_KERNEL);
+		if (!ether->rx_scratch) {
+			dev_err(&pdev->dev,
+				"Failed to allocate memory for rx_scratch\n");
+			npcm7xx_free_desc(netdev, true);
+			return -ENOMEM;
+		}
+	}
+
 	for (i = 0; i < RX_QUEUE_LEN; i++) {
 		unsigned int offset;
 
@@ -777,105 +882,37 @@
 		else
 			offset = sizeof(struct npcm7xx_rxbd) * (i + 1);
 
-		rdesc->next = ether->rdesc_phys + offset;
-		rdesc->sl = RX_OWN_DMA;
+		rdesc->next = cpu_to_le32(ether->rdesc_phys + offset);
+		rdesc->sl = cpu_to_le32(RX_OWN_DMA);
 
-		if (!get_new_skb(dev, i)) {
+		if (!get_new_skb(netdev, i)) {
 			dev_err(&pdev->dev, "get_new_skb() failed\n");
-
-			for (; i != 0; i--) {
-				dma_unmap_single(&dev->dev, (dma_addr_t)
-						 ((ether->rdesc + i)->buffer),
-						 roundup(MAX_PACKET_SIZE_W_CRC,
-							 4), DMA_FROM_DEVICE);
-				dev_kfree_skb_any(ether->rx_skb[i]);
-				ether->rx_skb[i] = NULL;
-			}
-
-			dma_free_coherent(&pdev->dev,
-					  sizeof(struct npcm7xx_txbd) *
-					  TX_QUEUE_LEN,
-					  ether->tdesc, ether->tdesc_phys);
-			dma_free_coherent(&pdev->dev,
-					  sizeof(struct npcm7xx_rxbd) *
-					  RX_QUEUE_LEN,
-					  ether->rdesc, ether->rdesc_phys);
-
+			npcm7xx_free_desc(netdev, true);
 			return -ENOMEM;
 		}
 	}
 
 	ether->start_rx_ptr = ether->rdesc_phys;
-	wmb();
 	for (i = 0; i < TX_QUEUE_LEN; i++)
 		ether->tx_skb[i] = NULL;
 
 	return 0;
 }
 
-/* This API must call with Tx/Rx stopped */
-static void npcm7xx_free_desc(struct net_device *dev,
-			      bool free_also_descriptors)
+static void npcm7xx_set_fifo_threshold(struct net_device *netdev)
 {
-	struct sk_buff *skb;
-	u32 i;
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	struct platform_device *pdev = ether->pdev;
-
-	for (i = 0; i < TX_QUEUE_LEN; i++) {
-		skb = ether->tx_skb[i];
-		if (skb) {
-			dma_unmap_single(&dev->dev, (dma_addr_t)((ether->tdesc +
-								  i)->buffer),
-					 skb->len, DMA_TO_DEVICE);
-			dev_kfree_skb_any(skb);
-			ether->tx_skb[i] = NULL;
-		}
-	}
-
-	for (i = 0; i < RX_QUEUE_LEN; i++) {
-		skb = ether->rx_skb[i];
-		if (skb) {
-			dma_unmap_single(&dev->dev, (dma_addr_t)((ether->rdesc +
-								   i)->buffer),
-					 roundup(MAX_PACKET_SIZE_W_CRC, 4),
-					 DMA_FROM_DEVICE);
-			dev_kfree_skb_any(skb);
-			ether->rx_skb[i] = NULL;
-		}
-	}
-
-	if (free_also_descriptors) {
-		if (ether->tdesc)
-			dma_free_coherent(&pdev->dev,
-					  sizeof(struct npcm7xx_txbd) *
-					  TX_QUEUE_LEN,
-					  ether->tdesc, ether->tdesc_phys);
-		ether->tdesc = NULL;
-
-		if (ether->rdesc)
-			dma_free_coherent(&pdev->dev,
-					  sizeof(struct npcm7xx_rxbd) *
-					  RX_QUEUE_LEN,
-					  ether->rdesc, ether->rdesc_phys);
-		ether->rdesc = NULL;
-	}
-}
-
-static void npcm7xx_set_fifo_threshold(struct net_device *dev)
-{
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	__le32 val;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	u32 val;
 
 	val = RXTHD | TXTHD | BLENGTH;
 	writel(val, (ether->reg + REG_FFTCR));
 }
 
-static void npcm7xx_return_default_idle(struct net_device *dev)
+static void npcm7xx_return_default_idle(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	__le32 val;
-	__le32 saved_bits;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	u32 val;
+	u32 saved_bits;
 
 	val = readl((ether->reg + REG_MCMDR));
 	saved_bits = val & (MCMDR_FDUP | MCMDR_OPMOD);
@@ -892,8 +929,7 @@
 		val = readl((ether->reg + REG_FFTCR));
 	} while (val == 0);
 
-	/*
-	 * Now we can verify if (ether->reg + REG_MCMDR).SWR became
+	/* Now we can verify if (ether->reg + REG_MCMDR).SWR became
 	 * 0 (probably it will be 0 on the first read).
 	 */
 	do {
@@ -904,56 +940,55 @@
 	writel(saved_bits, (ether->reg + REG_MCMDR));
 }
 
-static void npcm7xx_enable_mac_interrupt(struct net_device *dev)
+static void npcm7xx_enable_mac_interrupt(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	__le32 val;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	u32 val;
 
-	val = ENRXINTR |  /* Start of RX interrupts */
-		ENCRCE   |
-		EMRXOV   |
-		(ENPTLE * (!IS_VLAN)) | /* If we don't support VLAN we want interrupt on long packets */
-		ENRXGD   |
-		ENALIE   |
-		ENRP     |
-		ENMMP    |
-		ENDFO    |
-		/*   ENDENI   |  */  /* We don't need interrupt on DMA Early Notification */
-		ENRDU    |    /* We don't need interrupt on Receive Descriptor Unavailable Interrupt */
-		ENRXBERR |
-		/*   ENCFR    |  */
-		ENTXINTR |  /* Start of TX interrupts */
-		ENTXEMP  |
-		ENTXCP   |
-		ENTXDEF  |
-		ENNCS    |
-		ENTXABT  |
-		ENLC     |
-		/* ENTDU    |  */  /* We don't need interrupt on Transmit Descriptor Unavailable at start of operation */
-		ENTXBERR;
+	val = ENRXINTR |    /* Start of RX interrupts */
+	      ENCRCE   |
+	      EMRXOV   |
+	     (ENPTLE * !IS_VLAN)  |    /* If we don't support VLAN we want interrupt on long packets */
+	      ENRXGD   |
+	      ENALIE   |
+	      ENRP     |
+	      ENMMP    |
+	      ENDFO    |
+	   /* ENDENI   | */ /* We don't need interrupt on DMA Early Notification */
+	      ENRDU    |    /* We don't need interrupt on Receive Descriptor Unavailable Interrupt */
+	      ENRXBERR |
+	   /* ENCFR    | */
+	      ENTXINTR |    /* Start of TX interrupts */
+	      ENTXEMP  |
+	      ENTXCP   |
+	      ENTXDEF  |
+	      ENNCS    |
+	      ENTXABT  |
+	      ENLC     |
+	   /* ENTDU    | */ /* We don't need interrupt on Transmit Descriptor Unavailable at start of operation */
+	      ENTXBERR;
 	writel(val, (ether->reg + REG_MIEN));
 }
 
-static void npcm7xx_get_and_clear_int(struct net_device *dev,
-				      __le32 *val, __le32 mask)
+static void npcm7xx_get_and_clear_int(struct net_device *netdev,
+				      u32 *val, u32 mask)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 
 	*val = readl((ether->reg + REG_MISTA)) & mask;
 	writel(*val, (ether->reg + REG_MISTA));
 }
 
-static void npcm7xx_set_global_maccmd(struct net_device *dev)
+static void npcm7xx_set_global_maccmd(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	__le32 val;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	u32 val;
 
 	val = readl((ether->reg + REG_MCMDR));
 
 	val |= MCMDR_SPCRC | MCMDR_ENMDC | MCMDR_ACP | MCMDR_NDEF;
 	if (IS_VLAN) {
-		/*
-		 * we set ALP accept long packets since VLAN packets
+		/* we set ALP accept long packets since VLAN packets
 		 * are 4 bytes longer than 1518
 		 */
 		val |= MCMDR_ALP;
@@ -963,38 +998,38 @@
 	writel(val, (ether->reg + REG_MCMDR));
 }
 
-static void npcm7xx_enable_cam(struct net_device *dev)
+static void npcm7xx_enable_cam(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-	__le32 val;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+	u32 val;
 
-	npcm7xx_write_cam(dev, CAM0, dev->dev_addr);
+	npcm7xx_write_cam(netdev, CAM0, netdev->dev_addr);
 
 	val = readl((ether->reg + REG_CAMEN));
 	val |= CAM0EN;
 	writel(val, (ether->reg + REG_CAMEN));
 }
 
-static void npcm7xx_set_curdest(struct net_device *dev)
+static void npcm7xx_set_curdest(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 
 	writel(ether->start_rx_ptr, (ether->reg + REG_RXDLSA));
 	writel(ether->start_tx_ptr, (ether->reg + REG_TXDLSA));
 }
 
-static void npcm7xx_ether_set_rx_mode(struct net_device *dev)
+static void npcm7xx_ether_set_rx_mode(struct net_device *netdev)
 {
 	struct npcm7xx_ether *ether;
-	__le32 rx_mode;
+	u32 rx_mode;
 
-	ether = netdev_priv(dev);
+	ether = netdev_priv(netdev);
 
 	dev_dbg(&ether->pdev->dev, "%s CAMCMR_AUP\n",
-		(dev->flags & IFF_PROMISC) ? "Set" : "Clear");
-	if (dev->flags & IFF_PROMISC)
+		(netdev->flags & IFF_PROMISC) ? "Set" : "Clear");
+	if (netdev->flags & IFF_PROMISC)
 		rx_mode = CAMCMR_AUP | CAMCMR_AMP | CAMCMR_ABP | CAMCMR_ECMP;
-	else if ((dev->flags & IFF_ALLMULTI) || !netdev_mc_empty(dev))
+	else if ((netdev->flags & IFF_ALLMULTI) || !netdev_mc_empty(netdev))
 		rx_mode = CAMCMR_AMP | CAMCMR_ABP | CAMCMR_ECMP;
 	else
 		rx_mode = CAMCMR_ECMP | CAMCMR_ABP;
@@ -1002,23 +1037,32 @@
 	ether->camcmr = rx_mode;
 }
 
-static void npcm7xx_reset_mac(struct net_device *dev, int need_free)
+static void npcm7xx_rx_enable(struct net_device *netdev)
+{
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
+
+	/* enable RX */
+	writel(readl((ether->reg + REG_MCMDR)) | MCMDR_RXON,
+	       (ether->reg + REG_MCMDR));
+}
+
+static void npcm7xx_reset_mac(struct net_device *netdev, int need_free)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 
-	netif_tx_lock(dev);
+	netif_tx_lock(netdev);
 
 	/* disable RX and TX */
 	writel(readl((ether->reg + REG_MCMDR)) & ~(MCMDR_TXON | MCMDR_RXON),
 	       (ether->reg + REG_MCMDR));
 
-	npcm7xx_return_default_idle(dev);
-	npcm7xx_set_fifo_threshold(dev);
+	npcm7xx_return_default_idle(netdev);
+	npcm7xx_set_fifo_threshold(netdev);
 
 	if (need_free)
-		npcm7xx_free_desc(dev, false);
+		npcm7xx_free_desc(netdev, false);
 
-	npcm7xx_init_desc(dev);
+	npcm7xx_init_desc(netdev);
 
 	ether->cur_tx = 0x0;
 	ether->finish_tx = 0x0;
@@ -1028,23 +1072,20 @@
 	ether->tx_tdu_i = 0;
 	ether->tx_cp_i = 0;
 
-	npcm7xx_set_curdest(dev);
-	npcm7xx_enable_cam(dev);
-	npcm7xx_ether_set_rx_mode(dev);
-	npcm7xx_enable_mac_interrupt(dev);
-	npcm7xx_set_global_maccmd(dev);
+	npcm7xx_set_curdest(netdev);
+	npcm7xx_enable_cam(netdev);
+	npcm7xx_ether_set_rx_mode(netdev);
+	npcm7xx_enable_mac_interrupt(netdev);
+	npcm7xx_set_global_maccmd(netdev);
 
-	/* enable RX and TX */
-	writel(readl((ether->reg + REG_MCMDR)) | MCMDR_TXON | MCMDR_RXON,
+	/* enable TX */
+	writel(readl((ether->reg + REG_MCMDR)) | MCMDR_TXON,
 	       (ether->reg + REG_MCMDR));
 
-	/* trigger RX */
-	writel(ENSTART, (ether->reg + REG_RSDR));
-
 	ether->need_reset = 0;
 
-	netif_wake_queue(dev);
-	netif_tx_unlock(dev);
+	netif_wake_queue(netdev);
+	netif_tx_unlock(netdev);
 }
 
 static int npcm7xx_mdio_write(struct mii_bus *bus, int phy_id, int regnum,
@@ -1060,9 +1101,10 @@
 	/* Wait for completion */
 	while (readl((ether->reg + REG_MIIDA)) & PHYBUSY) {
 		if (time_after(jiffies, timeout)) {
-			dev_dbg(&ether->pdev->dev, "mdio read timed out\n ether->reg = 0x%x phy_id=0x%x REG_MIIDA=0x%x\n",
-				(unsigned int)ether->reg, phy_id
-				, readl((ether->reg + REG_MIIDA)));
+			dev_dbg(&ether->pdev->dev,
+				"mdio read timed out\n ether->reg = 0x%x phy_id=0x%x REG_MIIDA=0x%x\n",
+				(unsigned int)ether->reg, phy_id,
+				readl((ether->reg + REG_MIIDA)));
 			return -ETIMEDOUT;
 		}
 		cpu_relax();
@@ -1081,7 +1123,8 @@
 	/* Wait for completion */
 	while (readl((ether->reg + REG_MIIDA)) & PHYBUSY) {
 		if (time_after(jiffies, timeout)) {
-			dev_dbg(&ether->pdev->dev, "mdio read timed out\n ether->reg = 0x%x phy_id=0x%x REG_MIIDA=0x%x\n",
+			dev_dbg(&ether->pdev->dev,
+				"mdio read timed out\n ether->reg = 0x%x phy_id=0x%x REG_MIIDA=0x%x\n",
 				(unsigned int)ether->reg, phy_id
 				, readl((ether->reg + REG_MIIDA)));
 			return -ETIMEDOUT;
@@ -1098,61 +1141,63 @@
 	return 0;
 }
 
-static int npcm7xx_set_mac_address(struct net_device *dev, void *addr)
+static int npcm7xx_set_mac_address(struct net_device *netdev, void *addr)
 {
 	struct sockaddr *address = addr;
 
 	if (!is_valid_ether_addr((u8 *)address->sa_data))
 		return -EADDRNOTAVAIL;
 
-	memcpy(dev->dev_addr, address->sa_data, dev->addr_len);
-	npcm7xx_write_cam(dev, CAM0, dev->dev_addr);
+	memcpy(netdev->dev_addr, address->sa_data, netdev->addr_len);
+	npcm7xx_write_cam(netdev, CAM0, netdev->dev_addr);
 
 	return 0;
 }
 
-static int npcm7xx_ether_close(struct net_device *dev)
+static int npcm7xx_ether_close(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
-
-	npcm7xx_return_default_idle(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 
 	if (ether->phy_dev)
 		phy_stop(ether->phy_dev);
 	else if (ether->use_ncsi)
 		ncsi_stop_dev(ether->ncsidev);
 
-	msleep(20);
+	napi_disable(&ether->napi);
+	netif_stop_queue(netdev);
 
-	free_irq(ether->txirq, dev);
-	free_irq(ether->rxirq, dev);
+	npcm7xx_return_default_idle(netdev);
 
-	netif_stop_queue(dev);
-	napi_disable(&ether->napi);
+	msleep(20);
+
+	free_irq(ether->txirq, netdev);
+	free_irq(ether->rxirq, netdev);
 
-	npcm7xx_free_desc(dev, true);
+	npcm7xx_free_desc(netdev, true);
 
-	kfree(ether->dump_buf);
-	ether->dump_buf = NULL;
+	if (ether->dump_buf) {
+		kfree(ether->dump_buf);
+		ether->dump_buf = NULL;
+	}
 
 	return 0;
 }
 
-static struct net_device_stats *npcm7xx_ether_stats(struct net_device *dev)
+static struct net_device_stats *npcm7xx_ether_stats(struct net_device *netdev)
 {
 	struct npcm7xx_ether *ether;
 
-	ether = netdev_priv(dev);
+	ether = netdev_priv(netdev);
 	return &ether->stats;
 }
 
-static int npcm7xx_clean_tx(struct net_device *dev, bool from_xmit)
+static int npcm7xx_clean_tx(struct net_device *netdev, bool from_xmit)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct npcm7xx_txbd *txbd;
 	struct sk_buff *s;
 	dma_addr_t cur_entry, entry;
-	__le32 sl;
+	u32 sl;
 
 	if (ether->pending_tx == 0)
 		return (0);
@@ -1171,7 +1216,8 @@
 
 		ether->count_finish++;
 
-		dma_unmap_single(&dev->dev, txbd->buffer, s->len,
+		dma_unmap_single(&netdev->dev,
+				 (dma_addr_t)le32_to_cpu(txbd->buffer), s->len,
 				 DMA_TO_DEVICE);
 		consume_skb(s);
 		ether->tx_skb[ether->finish_tx] = NULL;
@@ -1180,7 +1226,7 @@
 			ether->finish_tx = 0;
 		ether->pending_tx--;
 
-		sl = txbd->sl;
+		sl = le32_to_cpu(txbd->sl);
 		if (sl & TXDS_TXCP) {
 			ether->stats.tx_packets++;
 			ether->stats.tx_bytes += (sl & 0xFFFF);
@@ -1192,40 +1238,50 @@
 			(ether->finish_tx);
 	}
 
-	if (!from_xmit && unlikely(netif_queue_stopped(dev) &&
+	if (!from_xmit && unlikely(netif_queue_stopped(netdev) &&
 				   (TX_QUEUE_LEN - ether->pending_tx) > 1)) {
-		netif_tx_lock(dev);
-		if (netif_queue_stopped(dev) &&
+		netif_tx_lock(netdev);
+		if (netif_queue_stopped(netdev) &&
 		    (TX_QUEUE_LEN - ether->pending_tx) > 1) {
-			netif_wake_queue(dev);
+			netif_wake_queue(netdev);
 		}
-		netif_tx_unlock(dev);
+		netif_tx_unlock(netdev);
 	}
 
 	return(0);
 }
 
-static int npcm7xx_ether_start_xmit(struct sk_buff *skb, struct net_device *dev)
+static int npcm7xx_ether_start_xmit(struct sk_buff *skb, struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct npcm7xx_txbd *txbd;
 	unsigned long flags;
 
+	if (skb->len > MAX_PACKET_SIZE) {
+		if (net_ratelimit())
+			netdev_warn(netdev,
+				    "skb->len = %d > MAX_PACKET_SIZE = %d\n",
+				    skb->len, MAX_PACKET_SIZE);
+		/* Drop the packet */
+		dev_kfree_skb_any(skb);
+		netdev->stats.tx_dropped++;
+		return NETDEV_TX_OK;
+	}
+
 	ether->count_xmit++;
 
 	/* Insert new buffer */
 	txbd = (ether->tdesc + ether->cur_tx);
-	txbd->buffer = dma_map_single(&dev->dev, skb->data, skb->len,
-				      DMA_TO_DEVICE);
+	txbd->buffer = cpu_to_le32(dma_map_single(&netdev->dev, skb->data,
+						  skb->len, DMA_TO_DEVICE));
 	ether->tx_skb[ether->cur_tx]  = skb;
-	if (skb->len > MAX_PACKET_SIZE)
-		dev_err(&ether->pdev->dev, "skb->len (= %d) > MAX_PACKET_SIZE (= %d)\n",
-			skb->len, MAX_PACKET_SIZE);
 
-	txbd->sl = skb->len > MAX_PACKET_SIZE ? MAX_PACKET_SIZE : skb->len;
+	txbd->sl = cpu_to_le32(skb->len);
 	dma_wmb();
 
-	txbd->mode = TX_OWN_DMA | PADDINGMODE | CRCMODE;
+	txbd->mode = cpu_to_le32(TX_OWN_DMA | PADDINGMODE | CRCMODE);
+
+	/* make sure that data is in memory before we trigger TX */
 	wmb();
 
 	/* trigger TX */
@@ -1237,10 +1293,13 @@
 	spin_lock_irqsave(&ether->lock, flags);
 	ether->pending_tx++;
 
-	npcm7xx_clean_tx(dev, true);
+	/* sometimes we miss the tx interrupt due to HW issue, so NAPI will not
+	 * clean the pending tx, so we clean it also here
+	 */
+	npcm7xx_clean_tx(netdev, true);
 
 	if (ether->pending_tx >= TX_QUEUE_LEN - 1) {
-		__le32 reg_mien;
+		u32 reg_mien;
 		unsigned int index_to_wake = ether->cur_tx +
 			((TX_QUEUE_LEN * 3) / 4);
 
@@ -1248,39 +1307,46 @@
 			index_to_wake -= TX_QUEUE_LEN;
 
 		txbd = (ether->tdesc + index_to_wake);
-		txbd->mode = TX_OWN_DMA | PADDINGMODE | CRCMODE | MACTXINTEN;
+		txbd->mode = cpu_to_le32(TX_OWN_DMA | PADDINGMODE | CRCMODE |
+					 MACTXINTEN);
+
+		/* make sure that data is in memory before we trigger TX */
 		wmb();
 
-		writel(MISTA_TDU, (ether->reg + REG_MISTA));
 		/* Clear TDU interrupt */
-		reg_mien = readl((ether->reg + REG_MIEN));
+		writel(MISTA_TDU, (ether->reg + REG_MISTA));
 
+		/* due to HW issue sometimes, we miss the TX interrupt we just
+		 * set (MACTXINTEN), so we also set TDU for Transmit
+		 * Descriptor Unavailable interrupt
+		 */
+		reg_mien = readl((ether->reg + REG_MIEN));
 		if (reg_mien != 0)
 			/* Enable TDU interrupt */
 			writel(reg_mien | ENTDU, (ether->reg + REG_MIEN));
 
 		ether->tx_tdu++;
-		netif_stop_queue(dev);
+		netif_stop_queue(netdev);
 	}
 
 	spin_unlock_irqrestore(&ether->lock, flags);
 
-	return 0;
+	return NETDEV_TX_OK;
 }
 
 static irqreturn_t npcm7xx_tx_interrupt(int irq, void *dev_id)
 {
 	struct npcm7xx_ether *ether;
 	struct platform_device *pdev;
-	struct net_device *dev;
-	__le32 status;
+	struct net_device *netdev;
+	u32 status;
 	unsigned long flags;
 
-	dev = dev_id;
-	ether = netdev_priv(dev);
+	netdev = dev_id;
+	ether = netdev_priv(netdev);
 	pdev = ether->pdev;
 
-	npcm7xx_get_and_clear_int(dev, &status, 0xFFFF0000);
+	npcm7xx_get_and_clear_int(netdev, &status, 0xFFFF0000);
 
 	ether->tx_int_count++;
 
@@ -1291,7 +1357,7 @@
 		dev_err(&pdev->dev, "emc bus error interrupt status=0x%08X\n",
 			status);
 #ifdef CONFIG_NPCM7XX_EMC_ETH_DEBUG
-		npcm7xx_info_print(dev);
+		npcm7xx_info_print(netdev);
 #endif
 		spin_lock_irqsave(&ether->lock, flags);
 		writel(0, (ether->reg + REG_MIEN)); /* disable any interrupt */
@@ -1301,10 +1367,12 @@
 		dev_err(&pdev->dev, "emc other error interrupt status=0x%08X\n",
 			status);
 
-    /* if we got MISTA_TXCP | MISTA_TDU remove those interrupt and call napi */
+	/* if we got MISTA_TXCP | MISTA_TDU remove those interrupt and call
+	 * napi
+	 */
 	if (status & (MISTA_TXCP | MISTA_TDU) &
 	    readl((ether->reg + REG_MIEN))) {
-		__le32 reg_mien;
+		u32 reg_mien;
 
 		spin_lock_irqsave(&ether->lock, flags);
 		reg_mien = readl((ether->reg + REG_MIEN));
@@ -1329,22 +1397,22 @@
 
 static irqreturn_t npcm7xx_rx_interrupt(int irq, void *dev_id)
 {
-	struct net_device *dev = (struct net_device *)dev_id;
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct net_device *netdev = (struct net_device *)dev_id;
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct platform_device *pdev = ether->pdev;
-	__le32 status;
+	u32 status;
 	unsigned long flags;
 	unsigned int any_err = 0;
-	__le32 rxfsm;
+	u32 rxfsm;
 
-	npcm7xx_get_and_clear_int(dev, &status, 0xFFFF);
+	npcm7xx_get_and_clear_int(netdev, &status, 0xFFFF);
 	ether->rx_int_count++;
 
 	if (unlikely(status & MISTA_RXBERR)) {
 		ether->rx_berr++;
 		dev_err(&pdev->dev, "emc rx bus error status=0x%08X\n", status);
 #ifdef CONFIG_NPCM7XX_EMC_ETH_DEBUG
-		npcm7xx_info_print(dev);
+		npcm7xx_info_print(netdev);
 #endif
 		spin_lock_irqsave(&ether->lock, flags);
 		writel(0, (ether->reg + REG_MIEN)); /* disable any interrupt */
@@ -1355,8 +1423,7 @@
 	}
 
 	if (unlikely(status & (MISTA_RXOV | MISTA_RDU))) {
-		/*
-		 * filter out all received packets until we have
+		/* filter out all received packets until we have
 		 * enough available buffer descriptors
 		 */
 		writel(0, (ether->reg + REG_CAMCMR));
@@ -1366,8 +1433,7 @@
 		if (status & (MISTA_RDU))
 			ether->rdu++;
 
-		/*
-		 * workaround Errata 1.36: EMC Hangs on receiving 253-256
+		/* workaround Errata 1.36: EMC Hangs on receiving 253-256
 		 * byte packet
 		 */
 		rxfsm = readl((ether->reg + REG_RXFSM));
@@ -1384,34 +1450,38 @@
 				ether->rx_stuck++;
 				spin_lock_irqsave(&ether->lock, flags);
 #ifdef CONFIG_NPCM7XX_EMC_ETH_DEBUG
-				npcm7xx_info_print(dev);
+				npcm7xx_info_print(netdev);
 #endif
 				writel(0,  (ether->reg + REG_MIEN));
 				spin_unlock_irqrestore(&ether->lock, flags);
 				ether->need_reset = 1;
 				    napi_schedule(&ether->napi);
-				dev_err(&pdev->dev, "stuck on REG_RXFSM = 0x%08X status=%08X doing reset!\n", rxfsm, status);
+				dev_err(&pdev->dev,
+					"stuck on REG_RXFSM = 0x%08X status=%08X doing reset!\n",
+					rxfsm, status);
 				return IRQ_HANDLED;
 			}
 		}
 	}
 
-	/* echo MISTA status on unexpected flags although we don't do anithing with them */
+	/* echo MISTA status on unexpected flags although we don't do anything
+	 * with them
+	 */
 	if (unlikely(status &
-		     (/* MISTA_RXINTR | */ /* Receive - all RX interrupt set this */
-			       MISTA_CRCE   |    /* CRC Error */
-			    /* MISTA_RXOV   | */ /* Receive FIFO Overflow - we alread handled it */
-			       (MISTA_PTLE * !IS_VLAN) | /* Packet Too Long is needed if VLAN is not supported */
-			    /* MISTA_RXGD   | */ /* Receive Good - this is the common good case */
-			       MISTA_ALIE   |    /* Alignment Error */
-			       MISTA_RP     |    /* Runt Packet */
-			       MISTA_MMP    |    /* More Missed Packet */
-			       MISTA_DFOI   |    /* Maximum Frame Length */
-			    /* MISTA_DENI   | */ /* DMA Early Notification - every packet get this */
-			    /* MISTA_RDU    | */ /* Receive Descriptor Unavailable */
-			    /* MISTA_RXBERR | */ /* Receive Bus Error Interrupt - we alread handled it */
-			    /* MISTA_CFR    | */ /* Control Frame Receive - not an error */
-				0))) {
+		(/* MISTA_RXINTR | */ /* Receive - all RX interrupt set this */
+		    MISTA_CRCE   |    /* CRC Error */
+		 /* MISTA_RXOV   | */ /* Receive FIFO Overflow - we already handled it */
+	(!IS_VLAN * MISTA_PTLE)  |    /* Packet Too Long is needed if VLAN is not supported */
+		 /* MISTA_RXGD   | */ /* Receive Good - this is the common good case */
+		    MISTA_ALIE   |    /* Alignment Error */
+		    MISTA_RP     |    /* Runt Packet */
+		    MISTA_MMP    |    /* More Missed Packet */
+		    MISTA_DFOI   |    /* Maximum Frame Length */
+		 /* MISTA_DENI   | */ /* DMA Early Notification - every packet get this */
+		 /* MISTA_RDU    | */ /* Receive Descriptor Unavailable */
+		 /* MISTA_RXBERR | */ /* Receive Bus Error Interrupt - we already handled it */
+		 /* MISTA_CFR    | */ /* Control Frame Receive - not an error */
+			0))) {
 		dev_dbg(&pdev->dev, "emc rx MISTA status=0x%08X\n", status);
 		any_err = 1;
 		ether->rx_err++;
@@ -1434,11 +1504,11 @@
 	struct npcm7xx_ether *ether =
 		container_of(napi, struct npcm7xx_ether, napi);
 	struct npcm7xx_rxbd *rxbd;
-	struct net_device *dev = ether->ndev;
+	struct net_device *netdev = ether->netdev;
 	struct platform_device *pdev = ether->pdev;
-	struct sk_buff *skb, *s;
+	struct sk_buff *s;
 	unsigned int length;
-	__le32 status;
+	u32 status;
 	unsigned long flags;
 	int rx_cnt = 0;
 	int complete = 0;
@@ -1453,8 +1523,7 @@
 		ether->max_waiting_rx = local_count;
 
 	if (local_count > (4 * RX_POLL_SIZE))
-		/*
-		 * we are porbably in a storm of short packets and we don't
+		/* we are probably in a storm of short packets and we don't
 		 * want to get into RDU since short packets in RDU cause
 		 * many RXOV which may cause EMC halt, so we filter out all
 		 * coming packets
@@ -1466,35 +1535,35 @@
 		writel(ether->camcmr, (ether->reg + REG_CAMCMR));
 
 	spin_lock_irqsave(&ether->lock, flags);
-	npcm7xx_clean_tx(dev, false);
+	npcm7xx_clean_tx(netdev, false);
 	spin_unlock_irqrestore(&ether->lock, flags);
 
 	rxbd = (ether->rdesc + ether->cur_rx);
 
 	while (rx_cnt < budget) {
-		status = rxbd->sl;
+		status = le32_to_cpu(rxbd->sl);
 		if ((status & RX_OWN_DMA) == RX_OWN_DMA) {
 			complete = 1;
 			break;
 		}
-		/* for debug puposes we save the previous value */
-		rxbd->reserved = status;
+		/* for debug purposes we save the previous value */
+		rxbd->reserved = cpu_to_le32(status);
 		s = ether->rx_skb[ether->cur_rx];
 		length = status & 0xFFFF;
 
-		/*
-		 * If VLAN is not supporte RXDS_PTLE (packet too long) is also
+		/* If VLAN is not supported RXDS_PTLE (packet too long) is also
 		 * an error
 		 */
 		if (likely((status & (RXDS_RXGD | RXDS_CRCE | RXDS_ALIE |
 				      RXDS_RP | (IS_VLAN ? 0 : RXDS_PTLE))) ==
 			   RXDS_RXGD) && likely(length <= MAX_PACKET_SIZE)) {
-			dma_unmap_single(&dev->dev, (dma_addr_t)rxbd->buffer,
+			dma_unmap_single(&netdev->dev,
+					 (dma_addr_t)le32_to_cpu(rxbd->buffer),
 					 roundup(MAX_PACKET_SIZE_W_CRC, 4),
 					 DMA_FROM_DEVICE);
 
 			skb_put(s, length);
-			s->protocol = eth_type_trans(s, dev);
+			s->protocol = eth_type_trans(s, netdev);
 			netif_receive_skb(s);
 			ether->stats.rx_packets++;
 			ether->stats.rx_bytes += length;
@@ -1502,26 +1571,8 @@
 			ether->rx_count_pool++;
 
 			/* now we allocate new skb instead if the used one. */
-			skb = dev_alloc_skb(roundup(MAX_PACKET_SIZE_W_CRC, 4));
-			if (!skb) {
-				dev_err(&pdev->dev, "get skb buffer error\n");
+			if (!get_new_skb(netdev, ether->cur_rx))
 				ether->stats.rx_dropped++;
-				goto rx_out;
-			}
-
-			/* Do not unmark the following skb_reserve() Receive
-			 * Buffer Starting Address must be aligned
-			 * to 4 bytes and the following line if unmarked
-			 * will make it align to 2 and this likely
-			 * will hult the RX and crash the linux
-			 * skb_reserve(skb, NET_IP_ALIGN);
-			 */
-			skb->dev = dev;
-
-			rxbd->buffer = dma_map_single(&dev->dev, skb->data,
-						      roundup(MAX_PACKET_SIZE_W_CRC, 4),
-						      DMA_FROM_DEVICE);
-			ether->rx_skb[ether->cur_rx] = skb;
 		} else {
 			ether->rx_err_count++;
 			ether->stats.rx_errors++;
@@ -1548,8 +1599,11 @@
 			}
 		}
 
+		/* make sure other values are set before we set owner */
 		wmb();
-		rxbd->sl = RX_OWN_DMA;
+
+		rxbd->sl = cpu_to_le32(RX_OWN_DMA);
+		/* make sure that data is in memory before we trigger RX */
 		wmb();
 
 		if (++ether->cur_rx >= RX_QUEUE_LEN)
@@ -1563,7 +1617,8 @@
 
 		if (ether->need_reset) {
 			dev_dbg(&pdev->dev, "Reset\n");
-			npcm7xx_reset_mac(dev, 1);
+			npcm7xx_reset_mac(netdev, 1);
+			npcm7xx_rx_enable(netdev);
 		}
 
 		spin_lock_irqsave(&ether->lock, flags);
@@ -1581,8 +1636,7 @@
 			ether->max_waiting_rx = local_count;
 
 		if (local_count > (3 * RX_POLL_SIZE))
-			/*
-			 * we are porbably in a storm of short packets and
+			/* we are probably in a storm of short packets and
 			 * we don't want to get into RDU since short packets in
 			 * RDU cause many RXOV which may cause
 			 * EMC halt, so we filter out all coming packets
@@ -1592,75 +1646,73 @@
 			/* we can restore accepting of packets */
 			writel(ether->camcmr, (ether->reg + REG_CAMCMR));
 	}
-rx_out:
 
 	/* trigger RX */
 	writel(ENSTART, (ether->reg + REG_RSDR));
 	return rx_cnt;
 }
 
-static int npcm7xx_ether_open(struct net_device *dev)
+static int npcm7xx_ether_open(struct net_device *netdev)
 {
 	struct npcm7xx_ether *ether;
 	struct platform_device *pdev;
 
-	ether = netdev_priv(dev);
+	ether = netdev_priv(netdev);
 	pdev = ether->pdev;
 
 	if (ether->use_ncsi) {
 		ether->speed = 100;
 		ether->duplex = DUPLEX_FULL;
-		npcm7xx_opmode(dev, 100, DUPLEX_FULL);
+		npcm7xx_opmode(netdev, 100, DUPLEX_FULL);
 	}
-	npcm7xx_reset_mac(dev, 0);
+	npcm7xx_reset_mac(netdev, 0);
 
 	if (request_irq(ether->txirq, npcm7xx_tx_interrupt, 0x0, pdev->name,
-			dev)) {
+			netdev)) {
 		dev_err(&pdev->dev, "register irq tx failed\n");
-		npcm7xx_ether_close(dev);
+		npcm7xx_ether_close(netdev);
 		return -EAGAIN;
 	}
 
 	if (request_irq(ether->rxirq, npcm7xx_rx_interrupt, 0x0, pdev->name,
-			dev)) {
+			netdev)) {
 		dev_err(&pdev->dev, "register irq rx failed\n");
-		npcm7xx_ether_close(dev);
+		npcm7xx_ether_close(netdev);
 		return -EAGAIN;
 	}
 
 	if (ether->phy_dev)
 		phy_start(ether->phy_dev);
 	else if (ether->use_ncsi)
-		netif_carrier_on(dev);
+		netif_carrier_on(netdev);
 
-	netif_start_queue(dev);
+	netif_start_queue(netdev);
 	napi_enable(&ether->napi);
 
-	/* trigger RX */
-	writel(ENSTART, (ether->reg + REG_RSDR));
+	npcm7xx_rx_enable(netdev);
 
 	/* Start the NCSI device */
 	if (ether->use_ncsi) {
 		int err = ncsi_start_dev(ether->ncsidev);
 
 		if (err) {
-			npcm7xx_ether_close(dev);
+			npcm7xx_ether_close(netdev);
 			return err;
 		}
 	}
 
-	dev_info(&pdev->dev, "%s is OPENED\n", dev->name);
+	dev_info(&pdev->dev, "%s is OPENED\n", netdev->name);
 
 	return 0;
 }
 
-static int npcm7xx_ether_ioctl(struct net_device *dev,
+static int npcm7xx_ether_ioctl(struct net_device *netdev,
 			       struct ifreq *ifr, int cmd)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct phy_device *phydev = ether->phy_dev;
 
-	if (!netif_running(dev))
+	if (!netif_running(netdev))
 		return -EINVAL;
 
 	if (!phydev)
@@ -1669,7 +1721,7 @@
 	return phy_mii_ioctl(phydev, ifr, cmd);
 }
 
-static void npcm7xx_get_drvinfo(struct net_device *dev,
+static void npcm7xx_get_drvinfo(struct net_device *netdev,
 				struct ethtool_drvinfo *info)
 {
 	strlcpy(info->driver, DRV_MODULE_NAME, sizeof(info->driver));
@@ -1678,10 +1730,10 @@
 	strlcpy(info->bus_info, "N/A", sizeof(info->bus_info));
 }
 
-static int npcm7xx_get_settings(struct net_device *dev,
+static int npcm7xx_get_settings(struct net_device *netdev,
 				struct ethtool_link_ksettings *cmd)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct phy_device *phydev = ether->phy_dev;
 
 	if (!phydev)
@@ -1693,10 +1745,10 @@
 	return 0;
 }
 
-static int npcm7xx_set_settings(struct net_device *dev,
+static int npcm7xx_set_settings(struct net_device *netdev,
 				const struct ethtool_link_ksettings *cmd)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct phy_device *phydev = ether->phy_dev;
 	int ret;
 
@@ -1709,16 +1761,16 @@
 	return ret;
 }
 
-static u32 npcm7xx_get_msglevel(struct net_device *dev)
+static u32 npcm7xx_get_msglevel(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 
 	return ether->msg_enable;
 }
 
-static void npcm7xx_set_msglevel(struct net_device *dev, u32 level)
+static void npcm7xx_set_msglevel(struct net_device *netdev, u32 level)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 
 	ether->msg_enable = level;
 }
@@ -1744,31 +1796,32 @@
 	.ndo_change_mtu		= eth_change_mtu,
 };
 
-static void get_mac_address(struct net_device *dev)
+static void get_mac_address(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct platform_device *pdev = ether->pdev;
 	struct device_node *np = ether->pdev->dev.of_node;
 	const u8 *mac_address = NULL;
 
 	mac_address = of_get_mac_address(np);
 
-	if (mac_address != 0)
-		ether_addr_copy(dev->dev_addr, mac_address);
-
-	if (is_valid_ether_addr(dev->dev_addr)) {
-		dev_info(&pdev->dev, "%s: device MAC address : %pM\n",
-			 pdev->name, dev->dev_addr);
+	if (IS_ERR(mac_address)) {
+		eth_hw_addr_random(netdev);
+		dev_info(&pdev->dev,
+			"%s: device MAC address (random generator) %pM\n",
+			netdev->name, netdev->dev_addr);
 	} else {
-		eth_hw_addr_random(dev);
-		dev_info(&pdev->dev, "%s: device MAC address (random generator) %pM\n",
-			 dev->name, dev->dev_addr);
+		ether_addr_copy(netdev->dev_addr, mac_address);
+		if (is_valid_ether_addr(netdev->dev_addr)) {
+			dev_info(&pdev->dev, "%s: device MAC address : %pM\n",
+			pdev->name, netdev->dev_addr);
+		}
 	}
 }
 
-static int npcm7xx_mii_setup(struct net_device *dev)
+static int npcm7xx_mii_setup(struct net_device *netdev)
 {
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 	struct platform_device *pdev;
 	struct phy_device *phydev = NULL;
 	int i, err = 0;
@@ -1816,7 +1869,7 @@
 	dev_info(&pdev->dev, " name = %s ETH-Phy-Id = 0x%x\n",
 		 phydev_name(phydev), phydev->phy_id);
 
-	phydev = phy_connect(dev, phydev_name(phydev),
+	phydev = phy_connect(netdev, phydev_name(phydev),
 			     &adjust_link,
 			     PHY_INTERFACE_MODE_RMII);
 
@@ -1829,10 +1882,10 @@
 		goto out3;
 	}
 
-	linkmode_and(phydev->supported, phydev->supported, PHY_BASIC_FEATURES);
-	linkmode_copy(phydev->advertising, phydev->supported);
 	ether->phy_dev = phydev;
 
+	phy_set_max_speed(phydev, SPEED_100);
+
 	return 0;
 
 out3:
@@ -1863,7 +1916,7 @@
 static int npcm7xx_ether_probe(struct platform_device *pdev)
 {
 	struct npcm7xx_ether *ether;
-	struct net_device *dev;
+	struct net_device *netdev;
 	int error;
 
 	struct clk *emc_clk = NULL;
@@ -1885,32 +1938,22 @@
 	if (error)
 		return -ENODEV;
 
-	dev = alloc_etherdev(sizeof(struct npcm7xx_ether));
-	if (!dev)
+	netdev = alloc_etherdev(sizeof(struct npcm7xx_ether));
+	if (!netdev)
 		return -ENOMEM;
 
-	ether = netdev_priv(dev);
+	ether = netdev_priv(netdev);
 
-	ether->rst_regmap =
-		syscon_regmap_lookup_by_compatible("nuvoton,npcm750-rst");
-	if (IS_ERR(ether->rst_regmap)) {
-		dev_err(&pdev->dev, "%s: failed to find nuvoton,npcm750-rst\n", __func__);
-		return IS_ERR(ether->rst_regmap);
+	ether->reset = devm_reset_control_get(&pdev->dev, NULL);
+	if (IS_ERR(ether->reset)) {
+		error = PTR_ERR(ether->reset);
+		goto failed_free;
 	}
 
 	/* Reset EMC module */
-	if (pdev->id == 0) {
-		regmap_update_bits(ether->rst_regmap, IPSRST1_OFFSET,
-				   (0x1 << 6), (0x1 << 6));
-		regmap_update_bits(ether->rst_regmap, IPSRST1_OFFSET,
-				   (0x1 << 6), 0);
-	}
-	if (pdev->id == 1) {
-		regmap_update_bits(ether->rst_regmap, IPSRST1_OFFSET,
-				   (0x1 << 21), (0x1 << 21));
-		regmap_update_bits(ether->rst_regmap, IPSRST1_OFFSET,
-				   (0x1 << 21), 0);
-	}
+	reset_control_assert(ether->reset);
+	udelay(5);
+	reset_control_deassert(ether->reset);
 
 	ether->res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	if (!ether->res) {
@@ -1950,51 +1993,28 @@
 		goto failed_free_io;
 	}
 
-	SET_NETDEV_DEV(dev, &pdev->dev);
-	platform_set_drvdata(pdev, dev);
-	ether->ndev = dev;
+	SET_NETDEV_DEV(netdev, &pdev->dev);
+	platform_set_drvdata(pdev, netdev);
+	ether->netdev = netdev;
 
 	ether->pdev = pdev;
 	ether->msg_enable = NETIF_MSG_LINK;
 
-	dev->netdev_ops = &npcm7xx_ether_netdev_ops;
-	dev->ethtool_ops = &npcm7xx_ether_ethtool_ops;
+	netdev->netdev_ops = &npcm7xx_ether_netdev_ops;
+	netdev->ethtool_ops = &npcm7xx_ether_ethtool_ops;
 
-	dev->tx_queue_len = TX_QUEUE_LEN;
-	dev->dma = 0x0;
-	dev->watchdog_timeo = TX_TIMEOUT;
+	netdev->tx_queue_len = TX_QUEUE_LEN;
+	netdev->dma = 0x0;
+	netdev->watchdog_timeo = TX_TIMEOUT;
 
-	get_mac_address(dev);
+	get_mac_address(netdev);
 
-	ether->cur_tx = 0x0;
-	ether->cur_rx = 0x0;
-	ether->finish_tx = 0x0;
-	ether->pending_tx = 0x0;
-	ether->link = 0;
 	ether->speed = 100;
 	ether->duplex = DUPLEX_FULL;
-	ether->need_reset = 0;
-	ether->dump_buf = NULL;
-	ether->rx_berr = 0;
-	ether->rx_err = 0;
-	ether->rdu = 0;
-	ether->rxov = 0;
-	ether->rx_stuck = 0;
-	/* debug counters */
-	ether->max_waiting_rx = 0;
-	ether->rx_count_pool = 0;
-	ether->count_xmit = 0;
-	ether->rx_int_count = 0;
-	ether->rx_err_count = 0;
-	ether->tx_int_count = 0;
-	ether->count_finish = 0;
-	ether->tx_tdu = 0;
-	ether->tx_tdu_i = 0;
-	ether->tx_cp_i = 0;
 
 	spin_lock_init(&ether->lock);
 
-	netif_napi_add(dev, &ether->napi, npcm7xx_poll, RX_POLL_SIZE);
+	netif_napi_add(netdev, &ether->napi, npcm7xx_poll, RX_POLL_SIZE);
 
 	if (pdev->dev.of_node &&
 	    of_get_property(pdev->dev.of_node, "use-ncsi", NULL)) {
@@ -2005,21 +2025,22 @@
 		}
 		dev_info(&pdev->dev, "Using NCSI interface\n");
 		ether->use_ncsi = true;
-		ether->ncsidev = ncsi_register_dev(dev, npcm7xx_ncsi_handler);
+		ether->ncsidev = ncsi_register_dev(netdev,
+						   npcm7xx_ncsi_handler);
 		if (!ether->ncsidev) {
 			error = -ENODEV;
 			goto failed_free_napi;
 		}
 	} else {
 		ether->use_ncsi = false;
-	error = npcm7xx_mii_setup(dev);
+	error = npcm7xx_mii_setup(netdev);
 	if (error < 0) {
 		dev_err(&pdev->dev, "npcm7xx_mii_setup err\n");
 		goto failed_free_napi;
 		}
 	}
 
-	error = register_netdev(dev);
+	error = register_netdev(netdev);
 	if (error != 0) {
 		dev_err(&pdev->dev, "register_netdev() failed\n");
 		error = -ENODEV;
@@ -2040,24 +2061,25 @@
 failed_free_mem:
 	release_mem_region(ether->res->start, resource_size(ether->res));
 failed_free:
-	free_netdev(dev);
+	free_netdev(netdev);
 
 	return error;
 }
 
 static int npcm7xx_ether_remove(struct platform_device *pdev)
 {
-	struct net_device *dev = platform_get_drvdata(pdev);
-	struct npcm7xx_ether *ether = netdev_priv(dev);
+	struct net_device *netdev = platform_get_drvdata(pdev);
+	struct npcm7xx_ether *ether = netdev_priv(netdev);
 
 #ifdef CONFIG_DEBUG_FS
 	debugfs_remove_recursive(ether->dbgfs_dir);
 #endif
+	netif_napi_del(&ether->napi);
 
-	unregister_netdev(dev);
+	unregister_netdev(netdev);
 
-	free_irq(ether->txirq, dev);
-	free_irq(ether->rxirq, dev);
+	free_irq(ether->txirq, netdev);
+	free_irq(ether->rxirq, netdev);
 
 	if (ether->phy_dev)
 		phy_disconnect(ether->phy_dev);
@@ -2067,8 +2089,9 @@
 	mdiobus_free(ether->mii_bus);
 
 	platform_set_drvdata(pdev, NULL);
-
-	free_netdev(dev);
+	iounmap(ether->reg);
+	release_mem_region(ether->res->start, resource_size(ether->res));
+	free_netdev(netdev);
 	return 0;
 }
 
